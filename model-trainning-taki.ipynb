{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10104145,"sourceType":"datasetVersion","datasetId":6194450},{"sourceId":10112778,"sourceType":"datasetVersion","datasetId":6238561}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Model Training - Taki","metadata":{}},{"cell_type":"markdown","source":"## Import libraries","metadata":{}},{"cell_type":"code","source":"!pip install albumentations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:01.216353Z","iopub.execute_input":"2024-12-07T15:08:01.217037Z","iopub.status.idle":"2024-12-07T15:08:10.283761Z","shell.execute_reply.started":"2024-12-07T15:08:01.216999Z","shell.execute_reply":"2024-12-07T15:08:10.282875Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# Set seed for reproducibility\nseed = np.random.randint(0, 1000000)\nprint(f\"The seed is: {seed}\")\n\n# Import necessary libraries\nimport os\n\n# Set environment variables before importing modules\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['PYTHONHASHSEED'] = str(seed)\nos.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n\n# Suppress warnings\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=Warning)\n\n# Import necessary modules\nimport logging\nimport random\n\n# Set seeds for random number generators in NumPy and Python\nnp.random.seed(seed)\nrandom.seed(seed)\n\n# Import TensorFlow and Keras\nimport tensorflow as tf\nfrom tensorflow import keras as tfk\nfrom tensorflow.keras import layers as tfkl\nfrom keras.utils import register_keras_serializable\nimport keras_cv\n\n# Set seed for TensorFlow\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)\n\n# Reduce TensorFlow verbosity\ntf.autograph.set_verbosity(0)\ntf.get_logger().setLevel(logging.ERROR)\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n\n# Print TensorFlow version\nprint(tf.__version__)\n\n# Import other libraries\nimport os\nimport math\nfrom PIL import Image\nfrom keras import backend as K\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport albumentations as A\nimport IPython.display as display\n\n# Configure plot display settings\nsns.set(font_scale=1.4)\nsns.set_style('white')\nplt.rc('font', size=14)\n%matplotlib inline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:10.285573Z","iopub.execute_input":"2024-12-07T15:08:10.285877Z","iopub.status.idle":"2024-12-07T15:08:27.077536Z","shell.execute_reply.started":"2024-12-07T15:08:10.285844Z","shell.execute_reply":"2024-12-07T15:08:27.076856Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preparations","metadata":{}},{"cell_type":"code","source":"tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:27.078414Z","iopub.execute_input":"2024-12-07T15:08:27.078905Z","iopub.status.idle":"2024-12-07T15:08:27.082775Z","shell.execute_reply.started":"2024-12-07T15:08:27.078878Z","shell.execute_reply":"2024-12-07T15:08:27.082045Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def auto_select_accelerator():\n    \"\"\"\n    Reference:\n        * https://www.kaggle.com/mgornergoogle/getting-started-with-100-flowers-on-tpu\n        * https://www.kaggle.com/xhlulu/ranzcr-efficientnet-tpu-training\n    \"\"\"\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n\n    return strategy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:27.085095Z","iopub.execute_input":"2024-12-07T15:08:27.085426Z","iopub.status.idle":"2024-12-07T15:08:27.099943Z","shell.execute_reply.started":"2024-12-07T15:08:27.085391Z","shell.execute_reply":"2024-12-07T15:08:27.099162Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"strategy = auto_select_accelerator()\nnumGPU = len(tf.config.list_physical_devices('GPU'))\nnumTPU = len(tf.config.list_logical_devices('TPU'))\nprint(\"Num GPUs Available: \", numGPU)\nprint(\"Num TPUs Available: \", numTPU)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:27.100850Z","iopub.execute_input":"2024-12-07T15:08:27.101220Z","iopub.status.idle":"2024-12-07T15:08:27.324230Z","shell.execute_reply.started":"2024-12-07T15:08:27.101183Z","shell.execute_reply":"2024-12-07T15:08:27.323289Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"# Set batch size for training\nBATCH_SIZE = 32\nif numTPU != 0:\n    BATCH_SIZE = strategy.num_replicas_in_sync * 32\n\nprint(f\"Batch size: {BATCH_SIZE}\")\n\n# Set learning rate for the optimiser\nLEARNING_RATE = 1e-3\n\n# Set early stopping patience threshold\nPATIENCE = 100\n\n# Set maximum number of training epochs\nEPOCHS = 1000\n\n# Set data split size for training and validation\nSPLITS_SIZE = 300","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:27.325508Z","iopub.execute_input":"2024-12-07T15:08:27.325894Z","iopub.status.idle":"2024-12-07T15:08:27.335010Z","shell.execute_reply.started":"2024-12-07T15:08:27.325856Z","shell.execute_reply":"2024-12-07T15:08:27.334305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_path = '/kaggle/input/new-marssoil/clean_mars.npz'\ndata = np.load(dataset_path)\nX = data[\"X_train\"]\ny = data[\"y_train\"]\n\nX = np.expand_dims(X, axis=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:27.336006Z","iopub.execute_input":"2024-12-07T15:08:27.336245Z","iopub.status.idle":"2024-12-07T15:08:28.398987Z","shell.execute_reply.started":"2024-12-07T15:08:27.336221Z","shell.execute_reply":"2024-12-07T15:08:28.398246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.shape, y.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:28.399998Z","iopub.execute_input":"2024-12-07T15:08:28.400273Z","iopub.status.idle":"2024-12-07T15:08:28.406558Z","shell.execute_reply.started":"2024-12-07T15:08:28.400247Z","shell.execute_reply":"2024-12-07T15:08:28.405625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split the paths (not the data) into training, validation, and test sets\nprint(\"Splitting data...\")\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=SPLITS_SIZE, random_state=seed, \n)\nprint(\"Data splitted!\")\n\nprint(f\"\\nNumber of images:\")\nprint(f\"Train: {len(X_train)}\")\nprint(f\"Validation: {len(X_val)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:28.407582Z","iopub.execute_input":"2024-12-07T15:08:28.407853Z","iopub.status.idle":"2024-12-07T15:08:28.519657Z","shell.execute_reply.started":"2024-12-07T15:08:28.407797Z","shell.execute_reply":"2024-12-07T15:08:28.518795Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set steps per epoch for training\nSTEPS_PER_EPOCH = y_train.shape[0] // BATCH_SIZE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:28.523566Z","iopub.execute_input":"2024-12-07T15:08:28.523867Z","iopub.status.idle":"2024-12-07T15:08:28.527617Z","shell.execute_reply.started":"2024-12-07T15:08:28.523829Z","shell.execute_reply":"2024-12-07T15:08:28.526745Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the category mapping\ncategory_map = {\n        0: 0,  # Background\n        1: 1,  # Soil\n        2: 2,  # Bedrock\n        3: 3,  # Sand\n        4: 4,  # Big Rock\n}\n\n\n# Calculate the correct number of classes after mapping\nNUM_CLASSES = len(set(category_map.values()))\nprint(f\"Number of original categories: {len(category_map)}\")\nprint(f\"Number of classes after mapping: {NUM_CLASSES}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:28.528607Z","iopub.execute_input":"2024-12-07T15:08:28.528883Z","iopub.status.idle":"2024-12-07T15:08:28.540764Z","shell.execute_reply.started":"2024-12-07T15:08:28.528842Z","shell.execute_reply":"2024-12-07T15:08:28.539930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_single_image(image, label, input_size=(64, 128)):\n    \"\"\"\n    Load a single image-label pair with the correct shape.\n    \"\"\"\n    # Read and preprocess the image\n    image = tf.cast(image, tf.float32) / 255.0\n\n    # Read and preprocess the label\n    label = tf.cast(label, tf.int32)\n\n    return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:28.541966Z","iopub.execute_input":"2024-12-07T15:08:28.542712Z","iopub.status.idle":"2024-12-07T15:08:28.554803Z","shell.execute_reply.started":"2024-12-07T15:08:28.542670Z","shell.execute_reply":"2024-12-07T15:08:28.554125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def apply_category_mapping(label):\n    \"\"\"\n    Apply category mapping to labels.\n    \"\"\"\n    keys_tensor = tf.constant(list(category_map.keys()), dtype=tf.int32)\n    vals_tensor = tf.constant(list(category_map.values()), dtype=tf.int32)\n    table = tf.lookup.StaticHashTable(\n        tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor),\n        default_value=0\n    )\n    return table.lookup(label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:28.555717Z","iopub.execute_input":"2024-12-07T15:08:28.555967Z","iopub.status.idle":"2024-12-07T15:08:28.564736Z","shell.execute_reply.started":"2024-12-07T15:08:28.555943Z","shell.execute_reply":"2024-12-07T15:08:28.563739Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def one_hot_encode_mask(mask, num_classes):\n    \"\"\"\n    Converts a segmentation mask into a one-hot encoded tensor.\n    \n    Parameters:\n    - mask (tf.Tensor): Input mask of shape (H, W) with class indices.\n    - num_classes (int): Number of classes for one-hot encoding.\n    \n    Returns:\n    - tf.Tensor: One-hot encoded mask of shape (H, W, num_classes).\n    \"\"\"\n    if not isinstance(mask, tf.Tensor):\n        mask = tf.convert_to_tensor(mask)\n    \n    # Create one-hot encoded tensor\n    one_hot_mask = tf.one_hot(mask, depth=num_classes)\n    \n    return one_hot_mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:28.565728Z","iopub.execute_input":"2024-12-07T15:08:28.565965Z","iopub.status.idle":"2024-12-07T15:08:28.575172Z","shell.execute_reply.started":"2024-12-07T15:08:28.565942Z","shell.execute_reply":"2024-12-07T15:08:28.574541Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"original_height = X_train[0].shape[0]\noriginal_width = X_train[0].shape[1]\n\ndef augment_dataset(X, y, augmentations_per_image):\n    X_augmented = []\n    y_augmented = []\n    \n    aug = A.Compose([\n        A.OneOf([\n            A.RandomSizedCrop(min_max_height=(30, 50), height=original_height, width=original_width, p=0.8),\n            A.PadIfNeeded(min_height=original_height, min_width=original_width, p=0.5)\n        ],p=1),\n        A.VerticalFlip(p=0.5),\n        A.OneOf([\n            A.ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n            A.GridDistortion(p=0.5),\n            A.OpticalDistortion(distort_limit=1, shift_limit=0.5, p=1),\n        ], p=0.8),\n        A.RandomGamma(p=0.8)\n    ])\n\n    for _ in range(augmentations_per_image):\n        for image, mask in zip(X, y):\n            augmented = aug(image=image, mask=mask)\n            X_augmented.append(augmented['image'])\n            y_augmented.append(augmented['mask'])\n    \n    X_augmented = np.array(X_augmented)\n    y_augmented = np.array(y_augmented)\n    \n    X_combined = np.concatenate((X, X_augmented), axis=0)\n    y_combined = np.concatenate((y, y_augmented), axis=0)\n\n    return X_combined, y_combined","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:28.576159Z","iopub.execute_input":"2024-12-07T15:08:28.576392Z","iopub.status.idle":"2024-12-07T15:08:28.587659Z","shell.execute_reply.started":"2024-12-07T15:08:28.576370Z","shell.execute_reply":"2024-12-07T15:08:28.586856Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def cutMix(x, y, prob = 0.5, seed = None):\n    if seed is None:\n        seed = np.random.randint(0, 1000000)\n\n    rand_prob = tf.random.uniform([], seed=seed)\n    augmenter = keras_cv.layers.Augmenter(\n        [\n            keras_cv.layers.CutMix(),\n        ],\n    )\n    inputs = {\"images\": x, \"segmentation_masks\": y}\n    if rand_prob < prob:\n        outputs = augmenter(inputs)\n        outputs['images'] = tf.cast(outputs['images'], tf.float32)\n        outputs['segmentation_masks'] = tf.cast(outputs['segmentation_masks'], tf.int32)\n        return outputs['images'], outputs['segmentation_masks']\n    else:\n        return tf.cast(x, tf.float32), tf.cast(y, tf.int32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:28.588523Z","iopub.execute_input":"2024-12-07T15:08:28.588788Z","iopub.status.idle":"2024-12-07T15:08:28.599987Z","shell.execute_reply.started":"2024-12-07T15:08:28.588750Z","shell.execute_reply":"2024-12-07T15:08:28.599227Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_dataset(image_paths, label_paths, batch_size, shuffle=True, augment=False, mix=False, seed=None):\n    \"\"\"\n    Create a memory-efficient TensorFlow dataset.\n    \"\"\"\n    if augment:\n        image_paths, label_paths = augment_dataset(image_paths, label_paths, 2)\n\n    \n    # Create dataset from file paths\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, label_paths)).cache()\n\n    if shuffle:\n        dataset = dataset.shuffle(buffer_size=batch_size * 2, seed=seed)\n\n    # Load images and labels\n    dataset = dataset.map(\n        load_single_image,\n        num_parallel_calls=tf.data.AUTOTUNE\n    )\n    \n    # Apply category mapping\n    dataset = dataset.map(\n        lambda x, y: (x, apply_category_mapping(y)),\n        num_parallel_calls=tf.data.AUTOTUNE\n    )\n\n    # One hot encode mask\n    dataset = dataset.map(\n        lambda x, y: (x, one_hot_encode_mask(y, NUM_CLASSES)),\n        num_parallel_calls=tf.data.AUTOTUNE\n    )\n\n\n    # Batch the data\n    dataset = dataset.batch(batch_size, drop_remainder=False)\n    \n    if mix:\n        dataset = dataset.map(\n            lambda x, y: cutMix(x, y,seed = seed),\n            num_parallel_calls=tf.data.AUTOTUNE\n        )\n        \n    \n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    \n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:28.600787Z","iopub.execute_input":"2024-12-07T15:08:28.601089Z","iopub.status.idle":"2024-12-07T15:08:28.610978Z","shell.execute_reply.started":"2024-12-07T15:08:28.601061Z","shell.execute_reply":"2024-12-07T15:08:28.610120Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create the datasets\nprint(\"Creating datasets...\")\ntrain_dataset = make_dataset(\n    X_train, y_train,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    augment=True,\n    mix=True,\n    seed=seed\n)\n\nval_dataset = make_dataset(\n    X_val, y_val,\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)\nprint(\"Datasets created!\")\n\n# Check the shape of the data\nfor images, labels in train_dataset.take(1):\n    input_shape = images.shape[1:]\n    print(f\"\\nInput shape: {input_shape}\")\n    print(\"Images shape:\", images.shape)\n    print(\"Labels shape:\", labels.shape)\n    print(\"Labels dtype:\", labels.dtype)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:28.611920Z","iopub.execute_input":"2024-12-07T15:08:28.612243Z","iopub.status.idle":"2024-12-07T15:08:39.597289Z","shell.execute_reply.started":"2024-12-07T15:08:28.612197Z","shell.execute_reply":"2024-12-07T15:08:39.596437Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_segmentation_colormap(num_classes):\n    \"\"\"\n    Create a linear colormap using a predefined palette.\n    Uses 'viridis' as default because it is perceptually uniform\n    and works well for colorblindness.\n    \"\"\"\n    return plt.cm.viridis(np.linspace(0, 1, num_classes))\n\ndef apply_colormap(label, colormap=None):\n    \"\"\"\n    Apply the colormap to a label.\n    \"\"\"\n    # Ensure label is 2D\n    label = np.squeeze(label)\n\n    if colormap is None:\n        num_classes = len(np.unique(label))\n        colormap = create_segmentation_colormap(num_classes)\n\n    # Apply the colormap\n    colored = colormap[label.astype(int)]\n\n    return colored\n\ndef plot_sample_batch(dataset, num_samples=3):\n    \"\"\"\n    Display some image and label pairs from the dataset.\n    \"\"\"\n    plt.figure(figsize=(15, 4*num_samples))\n\n    for images, labels in dataset.take(1):\n        labels_np = labels.numpy()\n        num_classes = len(np.unique(labels_np))\n        colormap = create_segmentation_colormap(num_classes)\n\n        for j in range(min(num_samples, len(images))):\n            # Plot original image\n            plt.subplot(num_samples, 2, j*2 + 1)\n            plt.imshow(images[j])\n            plt.title(f'Image {j+1}')\n            plt.axis('off')\n\n            # Plot colored label\n            plt.subplot(num_samples, 2, j*2 + 2)\n            colored_label = apply_colormap(labels_np[j], colormap)\n            plt.imshow(colored_label)\n            plt.title(f'Label {j+1}')\n            plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n    plt.close()\n\n# Visualize examples from the training set\nprint(\"Visualizing examples from the training set:\")\n# plot_sample_batch(train_dataset, num_samples=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:39.598619Z","iopub.execute_input":"2024-12-07T15:08:39.598934Z","iopub.status.idle":"2024-12-07T15:08:39.607663Z","shell.execute_reply.started":"2024-12-07T15:08:39.598907Z","shell.execute_reply":"2024-12-07T15:08:39.606780Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"def unet_block(input_tensor, filters, kernel_size=6, activation='relu', stack=2, name=''):\n    # Initialise the input tensor\n    x = input_tensor\n\n    # Apply a sequence of Conv2D, Batch Normalisation, and Activation layers for the specified number of stacks\n    for i in range(stack):\n        x = tfkl.Conv2D(filters, kernel_size=kernel_size, padding='same', name=name + 'conv' + str(i + 1))(x)\n        x = tfkl.BatchNormalization(name=name + 'bn' + str(i + 1))(x)\n        x = tfkl.Activation(activation, name=name + 'activation' + str(i + 1))(x)\n\n    # Return the transformed tensor\n    return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:39.608751Z","iopub.execute_input":"2024-12-07T15:08:39.609092Z","iopub.status.idle":"2024-12-07T15:08:39.627774Z","shell.execute_reply.started":"2024-12-07T15:08:39.609055Z","shell.execute_reply":"2024-12-07T15:08:39.627035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def attention_block(input_tensor, gating_tensor, inter_channels):\n    \"\"\"Attention block for U-Net.\"\"\"\n    theta_x = tfkl.Conv2D(inter_channels, kernel_size=1, strides=1, padding=\"same\")(input_tensor)\n    phi_g = tfkl.Conv2D(inter_channels, kernel_size=1, strides=1, padding=\"same\")(gating_tensor)\n    add_xg = tfkl.Add()([theta_x, phi_g])\n    act_xg = tfkl.Activation(\"relu\")(add_xg)\n    psi = tfkl.Conv2D(1, kernel_size=1, strides=1, padding=\"same\")(act_xg)\n    psi = tfkl.Activation(\"sigmoid\")(psi)\n    output = tfkl.Multiply()([input_tensor, psi])\n    return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:39.628926Z","iopub.execute_input":"2024-12-07T15:08:39.629709Z","iopub.status.idle":"2024-12-07T15:08:39.644678Z","shell.execute_reply.started":"2024-12-07T15:08:39.629672Z","shell.execute_reply":"2024-12-07T15:08:39.643861Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_unet_model(input_shape=(64, 128, 1), num_classes=NUM_CLASSES, seed=seed):\n    \n    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n\n    # Downsampling path\n    down_block_1 = unet_block(input_layer, 32, name='down_block1_')\n    d1 = tfkl.MaxPooling2D()(down_block_1)\n\n    down_block_2 = unet_block(d1, 64, name='down_block2_')\n    d2 = tfkl.MaxPooling2D()(down_block_2)\n\n    # Bottleneck with Squeeze-and-Excite\n    bottleneck = unet_block(d2, 128, name='bottleneck')\n\n    # Upsampling path\n    u1 = tfkl.UpSampling2D()(bottleneck)\n    attn1 = attention_block(down_block_2, u1, inter_channels=64)  # Add attention here\n    u1 = tfkl.Conv2D(64, kernel_size=1, padding='same')(u1)  # Match channels to attn1\n    u1 = tfkl.Add()([u1, attn1])\n    u1 = unet_block(u1, 64, name='up_block1_')\n\n    u2 = tfkl.UpSampling2D()(u1)\n    attn2 = attention_block(down_block_1, u2, inter_channels=32)  # Add attention here\n    u2 = tfkl.Conv2D(32, kernel_size=1, padding='same')(u2)  # Match channels to attn2\n    u2 = tfkl.Add()([u2, attn2])\n    u2 = unet_block(u2, 32, name='up_block2_')\n\n    # Output Layer\n    output_layer = tfkl.Conv2D(num_classes, kernel_size=1, padding='same', activation=\"softmax\", name='output_layer')(u2)\n\n    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='UNet')\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:39.645740Z","iopub.execute_input":"2024-12-07T15:08:39.646408Z","iopub.status.idle":"2024-12-07T15:08:39.659503Z","shell.execute_reply.started":"2024-12-07T15:08:39.646372Z","shell.execute_reply":"2024-12-07T15:08:39.658677Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with strategy.scope():\n    model = get_unet_model()\n\n# Print a detailed summary of the model with expanded nested layers and trainable parameters.\nmodel.summary(expand_nested=True, show_trainable=True)\n\n# Generate and display a graphical representation of the model architecture.\ntf.keras.utils.plot_model(model, show_trainable=True, expand_nested=True, dpi=70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:39.660639Z","iopub.execute_input":"2024-12-07T15:08:39.660978Z","iopub.status.idle":"2024-12-07T15:08:40.379483Z","shell.execute_reply.started":"2024-12-07T15:08:39.660942Z","shell.execute_reply":"2024-12-07T15:08:40.378614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MeanIntersectionOverUnion(tf.keras.metrics.MeanIoU):\n    def __init__(self, num_classes, labels_to_exclude=None, name=\"mean_iou\", dtype=None):\n        super(MeanIntersectionOverUnion, self).__init__(num_classes=num_classes, name=name, dtype=dtype)\n        if labels_to_exclude is None:\n            labels_to_exclude = [0]  # Default to excluding label 0\n        self.labels_to_exclude = labels_to_exclude\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        # Convert predictions to class labels\n        y_pred = tf.math.argmax(y_pred, axis=-1)\n        y_true = tf.math.argmax(y_true, axis=-1)\n\n\n        # Flatten the tensors\n        y_true = tf.reshape(y_true, [-1])\n        y_pred = tf.reshape(y_pred, [-1])\n\n        # Apply mask to exclude specified labels\n        for label in self.labels_to_exclude:\n            mask = tf.not_equal(y_true, label)\n            y_true = tf.boolean_mask(y_true, mask)\n            y_pred = tf.boolean_mask(y_pred, mask)\n\n        # Update the state\n        return super().update_state(y_true, y_pred, sample_weight)\n\n# Visualization callback\nclass VizCallback(tf.keras.callbacks.Callback):\n    def __init__(self, image_path, label_path, frequency=5, output_dir='visualizations'):\n        super().__init__()\n        self.image_path = image_path\n        self.label_path = label_path\n        self.frequency = frequency\n        self.output_dir = output_dir\n\n    def on_epoch_end(self, epoch, logs=None):\n        if epoch % self.frequency == 0:  # Visualize only every \"frequency\" epochs\n            image, label = load_single_image(self.image_path, self.label_path)\n            label = apply_category_mapping(label)\n            image = tf.expand_dims(image, 0)\n            pred = self.model.predict(image, verbose=0)\n            y_pred = tf.math.argmax(pred, axis=-1)\n            y_pred = y_pred.numpy()\n\n            # Create colormap\n            num_classes = NUM_CLASSES\n            colormap = create_segmentation_colormap(num_classes)\n\n            # Prepare directory for saving images\n            epoch_dir = os.path.join(self.output_dir, f\"Epoch{epoch}\")\n            os.makedirs(epoch_dir, exist_ok=True)\n\n            plt.figure(figsize=(16, 4))\n\n            # Input image\n            plt.subplot(1, 3, 1)\n            plt.imshow(image[0])\n            plt.title(\"Input Image\")\n            plt.axis('off')\n\n            # Ground truth\n            plt.subplot(1, 3, 2)\n            colored_label = apply_colormap(label.numpy(), colormap)\n            plt.imshow(colored_label)\n            plt.title(\"Ground Truth Mask\")\n            plt.axis('off')\n            # Prediction\n            plt.subplot(1, 3, 3)\n            colored_pred = apply_colormap(y_pred[0], colormap)\n            plt.imshow(colored_pred)\n            plt.title(\"Predicted Mask\")\n            plt.axis('off')\n            predicted_mask_path = os.path.join(epoch_dir, \"predicted_mask.png\")\n            plt.savefig(predicted_mask_path)\n\n            plt.tight_layout()\n            plt.show()\n            plt.close()\n\n# Custom callback class for real-time plotting\nclass RealTimePlot(tf.keras.callbacks.Callback):\n    def on_train_begin(self, logs=None):\n        # Initialize the lists that will store the metrics\n        self.epochs = []\n        self.train_loss = []\n        self.val_loss = []\n        self.train_acc = []\n        self.val_acc = []\n\n        # Set up the plot\n        self.fig, (self.ax_loss, self.ax_acc) = plt.subplots(1, 2, figsize=(14, 5))\n        plt.show()\n\n    def on_epoch_end(self, epoch, logs=None):\n        # Append the metrics to the lists\n        self.epochs.append(epoch)\n        self.train_loss.append(logs['loss'])\n        self.val_loss.append(logs['val_loss'])\n        self.train_acc.append(logs['mean_iou'])\n        self.val_acc.append(logs['val_mean_iou'])\n\n        # Clear the previous output\n        display.clear_output(wait=True)\n\n        # Plot training and validation loss\n        self.ax_loss.clear()\n        self.ax_loss.plot(self.epochs, self.train_loss, label='Training Loss')\n        self.ax_loss.plot(self.epochs, self.val_loss, label='Validation Loss')\n        self.ax_loss.set_title('Training and Validation Loss')\n        self.ax_loss.set_xlabel('Epoch')\n        self.ax_loss.set_ylabel('Loss')\n        #self.ax_loss.set_ylim(top=2.5, bottom=0.0)\n        self.ax_loss.legend()\n\n        # Plot training and validation accuracy\n        self.ax_acc.clear()\n        self.ax_acc.plot(self.epochs, self.train_acc, label='Training Mean IOU')\n        self.ax_acc.plot(self.epochs, self.val_acc, label='Validation Mean IOU')\n        self.ax_acc.set_title('Training and Validation Mean IOU')\n        self.ax_acc.set_xlabel('Epoch')\n        self.ax_acc.set_ylabel('Mean IOU')\n        self.ax_acc.legend()\n\n        # Redraw the updated plots\n        display.display(self.fig)\n        plt.pause(0.1)\n\n# Custom implementation of ReduceLROnPlateau\nclass CustomReduceLROnPlateau(tf.keras.callbacks.Callback):\n    def __init__(self, monitor='val_accuracy', factor=0.33, patience=20, min_lr=1e-8, verbose=1):\n        super(CustomReduceLROnPlateau, self).__init__()\n        self.monitor = monitor\n        self.factor = factor\n        self.patience = patience\n        self.min_lr = min_lr\n        self.verbose = verbose\n        self.wait = 0\n        self.best = None\n        self.new_lr = None\n\n    def on_epoch_end(self, epoch, logs=None):\n        current = logs.get(self.monitor)\n        \n        # Initialize best metric if it's the first epoch\n        if self.best is None:\n            self.best = current\n            return\n\n        # Check if the monitored metric has improved\n        if current > self.best:\n            self.best = current\n            self.wait = 0\n        else:\n            self.wait += 1\n\n            # If patience is exceeded, reduce the learning rate\n            if self.wait >= self.patience:\n                old_lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n                if old_lr == self.min_lr:\n                    return\n                self.new_lr = max(old_lr * self.factor, self.min_lr)\n                self.model.optimizer.learning_rate.assign(self.new_lr)\n                \n                if self.verbose > 0:\n                    print(f\"\\nEpoch {epoch + 1}: reducing learning rate to {self.new_lr}.\")\n                \n                self.wait = 0  # Reset patience counter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:40.380629Z","iopub.execute_input":"2024-12-07T15:08:40.380975Z","iopub.status.idle":"2024-12-07T15:08:40.400768Z","shell.execute_reply.started":"2024-12-07T15:08:40.380947Z","shell.execute_reply":"2024-12-07T15:08:40.399864Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GeneralizedDiceLoss(tf.keras.losses.Loss):\n    def call(self, y_true, y_pred):\n        # Ensure y_pred is normalized (softmax output)\n        y_pred = tf.convert_to_tensor(y_pred)\n        y_true = tf.convert_to_tensor(y_true)\n        \n        # Compute weights\n        weights = 1.0 / (tf.reduce_sum(y_true, axis=[0, 1, 2])**2 + 1e-9)\n        \n        # Compute numerator\n        numerator = tf.reduce_sum(weights * tf.reduce_sum(y_true * y_pred, axis=[0, 1, 2]))\n        \n        # Compute denominator\n        denominator = tf.reduce_sum(weights * tf.reduce_sum(y_true + y_pred, axis=[0, 1, 2]))\n        \n        # Compute Generalized Dice coefficient\n        dice = 2.0 * (numerator + 1e-9) / (denominator + 1e-9)\n        \n        # Return Generalized Dice loss\n        return 1.0 - dice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:40.401616Z","iopub.execute_input":"2024-12-07T15:08:40.401941Z","iopub.status.idle":"2024-12-07T15:08:40.423343Z","shell.execute_reply.started":"2024-12-07T15:08:40.401917Z","shell.execute_reply":"2024-12-07T15:08:40.422472Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def weighted_categorical_crossentropy(weights):\n    # weights = [0.9, 0.05, 0.04, 0.01]\n    weights = tf.constant(weights, dtype=tf.float32)\n    \n    def wcce(y_true, y_pred):\n        # Ensure y_pred is a tensor and dtype matches\n        y_pred = tf.convert_to_tensor(y_pred)\n        \n        # Compute the standard categorical cross-entropy\n        cce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n        \n        # Apply weights to the true labels\n        weighted_sum = tf.reduce_sum(y_true * weights, axis=-1)\n        \n        # Return the weighted loss\n        return cce * weighted_sum\n    return wcce","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:40.424373Z","iopub.execute_input":"2024-12-07T15:08:40.424615Z","iopub.status.idle":"2024-12-07T15:08:40.437955Z","shell.execute_reply.started":"2024-12-07T15:08:40.424592Z","shell.execute_reply":"2024-12-07T15:08:40.437172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def dice_loss(y_true, y_pred, smooth=1):\n    y_true_f = tf.reshape(y_true, [-1])\n    y_pred_f = tf.reshape(y_pred, [-1])\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n    return 1 - (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n\ndef focal_loss(y_true, y_pred, alpha=0.25, gamma=2.0):\n    epsilon = tf.keras.backend.epsilon()\n    y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n    cross_entropy = -y_true * tf.math.log(y_pred)\n    weight = alpha * tf.pow(1 - y_pred, gamma)\n    return tf.reduce_sum(weight * cross_entropy, axis=-1)\n\ndef boundary_loss(y_true, y_pred):\n    def sobel_filters(x):\n        sobel = tf.image.sobel_edges(x)\n        sobel_x = sobel[..., 0]\n        sobel_y = sobel[..., 1]\n        return tf.sqrt(tf.square(sobel_x) + tf.square(sobel_y))\n    \n    y_true_edges = sobel_filters(y_true)\n    y_pred_edges = sobel_filters(y_pred)\n    return tf.reduce_mean(tf.square(y_true_edges - y_pred_edges))\n\ndef combined_loss(y_true, y_pred, w_dice=1.0, w_focal=1.5, w_boundary=0.5):\n    return (w_dice * dice_loss(y_true, y_pred) +\n            w_focal * focal_loss(y_true, y_pred) +\n            w_boundary * boundary_loss(y_true, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:40.439050Z","iopub.execute_input":"2024-12-07T15:08:40.439339Z","iopub.status.idle":"2024-12-07T15:08:40.448449Z","shell.execute_reply.started":"2024-12-07T15:08:40.439316Z","shell.execute_reply":"2024-12-07T15:08:40.447782Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"l2_lambda = 5e-2\n\nweights = [0.0,0.1,0.2,0.3,0.4]\n\n# Compile the model\nprint(\"Compiling model...\")\nwith strategy.scope():\n    model.compile(\n        loss= weighted_categorical_crossentropy(weights),\n        optimizer=tf.keras.optimizers.AdamW(LEARNING_RATE,  weight_decay=l2_lambda),\n        metrics=[\"accuracy\", MeanIntersectionOverUnion(num_classes=NUM_CLASSES, labels_to_exclude=[0])]\n    )\nprint(\"Model compiled!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:40.452707Z","iopub.execute_input":"2024-12-07T15:08:40.452959Z","iopub.status.idle":"2024-12-07T15:08:40.479440Z","shell.execute_reply.started":"2024-12-07T15:08:40.452936Z","shell.execute_reply":"2024-12-07T15:08:40.478750Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Setup callbacks\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_mean_iou',\n    mode='max',\n    patience=PATIENCE,\n    restore_best_weights=True\n)\n\nreduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau(\n                                            monitor=\"val_loss\",\n                                            factor=0.5,\n                                            patience=50,\n                                            verbose=0,\n                                            mode=\"auto\",\n                                            min_delta=0.0001,\n                                            cooldown=0,\n                                            min_lr=0.0,\n                                        )\n\nplot_callback = RealTimePlot()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:40.480415Z","iopub.execute_input":"2024-12-07T15:08:40.481066Z","iopub.status.idle":"2024-12-07T15:08:40.487346Z","shell.execute_reply.started":"2024-12-07T15:08:40.481027Z","shell.execute_reply":"2024-12-07T15:08:40.486179Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(\n    train_dataset,\n    epochs=EPOCHS,\n    validation_data=val_dataset,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[early_stopping, reduceLROnPlateau, plot_callback, VizCallback(X_val[100], y_val[100])],\n    shuffle = True,\n    verbose=1\n).history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:08:40.488358Z","iopub.execute_input":"2024-12-07T15:08:40.488712Z","iopub.status.idle":"2024-12-07T15:35:23.128954Z","shell.execute_reply.started":"2024-12-07T15:08:40.488667Z","shell.execute_reply":"2024-12-07T15:35:23.128209Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate and print the final validation accuracy\nfinal_val_meanIoU = round(max(history['val_mean_iou'])* 100, 2)\nprint(f'Final validation Mean Intersection Over Union: {final_val_meanIoU}%')\n\nwith strategy.scope():\n    # Save the trained model to a file with the accuracy included in the filename\n    model_filename = 'UNet_'+str(final_val_meanIoU)+'.keras'\n    model.save(model_filename)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:35:23.130897Z","iopub.execute_input":"2024-12-07T15:35:23.131162Z","iopub.status.idle":"2024-12-07T15:35:23.439869Z","shell.execute_reply.started":"2024-12-07T15:35:23.131137Z","shell.execute_reply":"2024-12-07T15:35:23.439174Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"test_path = \"/kaggle/input/marssoil/mars_for_students.npz\"\n\ntest_data = np.load(test_path)\nX_test = test_data[\"test_set\"]\n\nX_test = X_test[..., np.newaxis] / 255.0\n\nprint(f\"Input shape: {input_shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:35:23.440793Z","iopub.execute_input":"2024-12-07T15:35:23.441065Z","iopub.status.idle":"2024-12-07T15:35:25.082852Z","shell.execute_reply.started":"2024-12-07T15:35:23.441039Z","shell.execute_reply":"2024-12-07T15:35:25.081997Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preds = model.predict(X_test)\npreds = np.argmax(preds, axis=-1)\nprint(f\"Predictions shape: {preds.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:35:25.084168Z","iopub.execute_input":"2024-12-07T15:35:25.084553Z","iopub.status.idle":"2024-12-07T15:35:40.046700Z","shell.execute_reply.started":"2024-12-07T15:35:25.084513Z","shell.execute_reply":"2024-12-07T15:35:40.045798Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndef y_to_df(y) -> pd.DataFrame:\n    \"\"\"Converts segmentation predictions into a DataFrame format for Kaggle.\"\"\"\n    n_samples = len(y)\n    y_flat = y.reshape(n_samples, -1)\n    df = pd.DataFrame(y_flat)\n    df[\"id\"] = np.arange(n_samples)\n    cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n    return df[cols]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:35:40.047672Z","iopub.execute_input":"2024-12-07T15:35:40.047950Z","iopub.status.idle":"2024-12-07T15:35:40.053016Z","shell.execute_reply.started":"2024-12-07T15:35:40.047922Z","shell.execute_reply":"2024-12-07T15:35:40.052120Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create and download the csv submission file\ntimestep_str = model_filename.replace(\"model_\", \"\").replace(\".keras\", \"\")\nsubmission_filename = f\"submission_{timestep_str}.csv\"\nsubmission_df = y_to_df(preds)\nsubmission_df.to_csv(submission_filename, index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:35:40.054042Z","iopub.execute_input":"2024-12-07T15:35:40.054294Z","iopub.status.idle":"2024-12-07T15:36:02.388670Z","shell.execute_reply.started":"2024-12-07T15:35:40.054270Z","shell.execute_reply":"2024-12-07T15:36:02.387699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}